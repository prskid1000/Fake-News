{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-30T08:50:03.352102Z",
     "iopub.status.busy": "2021-11-30T08:50:03.351695Z",
     "iopub.status.idle": "2021-11-30T08:50:03.380794Z",
     "shell.execute_reply": "2021-11-30T08:50:03.380155Z",
     "shell.execute_reply.started": "2021-11-30T08:50:03.352013Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T08:50:03.382908Z",
     "iopub.status.busy": "2021-11-30T08:50:03.382432Z",
     "iopub.status.idle": "2021-11-30T08:50:24.384428Z",
     "shell.execute_reply": "2021-11-30T08:50:24.383729Z",
     "shell.execute_reply.started": "2021-11-30T08:50:03.382868Z"
    }
   },
   "outputs": [],
   "source": [
    "#dependencies\n",
    "!pip install contractions\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import contractions\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Conv1D, MaxPooling1D, Dropout, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import gensim\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow  as tf \n",
    "from tensorflow.keras.models import Model, load_model\n",
    "#from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping, ModelCheckpoint\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "import transformers\n",
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T08:50:24.386378Z",
     "iopub.status.busy": "2021-11-30T08:50:24.385649Z",
     "iopub.status.idle": "2021-11-30T08:50:27.613744Z",
     "shell.execute_reply": "2021-11-30T08:50:27.613015Z",
     "shell.execute_reply.started": "2021-11-30T08:50:24.386334Z"
    }
   },
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv(\"/kaggle/input/fake-news/train.csv\", header=0, index_col=0)\n",
    "df_t = pd.read_csv(\"/kaggle/input/fake-news/test.csv\", header=0, index_col=0)\n",
    "df_2 = df_2.drop(['title','author'], axis = 1)\n",
    "df_t = df_t.drop(['title','author'], axis = 1)\n",
    "df_2.dropna(inplace = True)\n",
    "df_t.fillna('',inplace = True)\n",
    "#print(df_2.isnull().sum(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T08:50:37.012555Z",
     "iopub.status.busy": "2021-11-30T08:50:37.012246Z",
     "iopub.status.idle": "2021-11-30T08:50:37.017062Z",
     "shell.execute_reply": "2021-11-30T08:50:37.016464Z",
     "shell.execute_reply.started": "2021-11-30T08:50:37.012527Z"
    }
   },
   "outputs": [],
   "source": [
    "#functions\n",
    "def regular_encode(texts, tokenizer, maxlen = 512 ):\n",
    "    enc_di = tokenizer.batch_encode_plus(texts,return_attention_mask = False, return_token_type_ids  = False,\n",
    "                                        pad_to_max_length = True, max_length = maxlen, truncation = True)\n",
    "    return np.array(enc_di[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T08:50:41.123154Z",
     "iopub.status.busy": "2021-11-30T08:50:41.122321Z",
     "iopub.status.idle": "2021-11-30T08:50:41.129583Z",
     "shell.execute_reply": "2021-11-30T08:50:41.128699Z",
     "shell.execute_reply.started": "2021-11-30T08:50:41.123095Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(transformer,maxlen = 512):\n",
    "    input_word_ids = Input(shape=(maxlen,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    sequence_output = transformer(input_word_ids)[0]\n",
    "    cls_token = sequence_output[:, 0, :]\n",
    "    out = Dense(1, activation='sigmoid')(cls_token)\n",
    "    \n",
    "    model = Model(inputs=input_word_ids, outputs=out)\n",
    "    model.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T08:50:42.562035Z",
     "iopub.status.busy": "2021-11-30T08:50:42.561737Z",
     "iopub.status.idle": "2021-11-30T08:50:48.459726Z",
     "shell.execute_reply": "2021-11-30T08:50:48.459023Z",
     "shell.execute_reply.started": "2021-11-30T08:50:42.562002Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T08:50:48.461752Z",
     "iopub.status.busy": "2021-11-30T08:50:48.461354Z",
     "iopub.status.idle": "2021-11-30T08:50:48.869174Z",
     "shell.execute_reply": "2021-11-30T08:50:48.868292Z",
     "shell.execute_reply.started": "2021-11-30T08:50:48.461724Z"
    }
   },
   "outputs": [],
   "source": [
    "from kaggle_datasets import KaggleDatasets\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Data access\n",
    "GCS_DS_PATH = KaggleDatasets().get_gcs_path()\n",
    "\n",
    "# Configuration\n",
    "EPOCHS = 2\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "MAX_LEN = 152\n",
    "MODEL = 'jplu/tf-xlm-roberta-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T08:50:51.121984Z",
     "iopub.status.busy": "2021-11-30T08:50:51.121675Z",
     "iopub.status.idle": "2021-11-30T08:50:54.850168Z",
     "shell.execute_reply": "2021-11-30T08:50:54.849258Z",
     "shell.execute_reply.started": "2021-11-30T08:50:51.121949Z"
    }
   },
   "outputs": [],
   "source": [
    "#from transformers import TFAutoModel, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T08:50:54.852750Z",
     "iopub.status.busy": "2021-11-30T08:50:54.852445Z",
     "iopub.status.idle": "2021-11-30T08:50:54.860521Z",
     "shell.execute_reply": "2021-11-30T08:50:54.859784Z",
     "shell.execute_reply.started": "2021-11-30T08:50:54.852718Z"
    }
   },
   "outputs": [],
   "source": [
    "train = df_2[['text', 'label']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T08:50:54.861649Z",
     "iopub.status.busy": "2021-11-30T08:50:54.861451Z",
     "iopub.status.idle": "2021-11-30T08:51:48.741973Z",
     "shell.execute_reply": "2021-11-30T08:51:48.741256Z",
     "shell.execute_reply.started": "2021-11-30T08:50:54.861626Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = regular_encode(list(train.text.values), tokenizer, maxlen=MAX_LEN)\n",
    "#x_valid = regular_encode(list(x_text.text.values), tokenizer, maxlen=MAX_LEN)\n",
    "x_test = regular_encode(list(df_t.text.values), tokenizer, maxlen=MAX_LEN)\n",
    "\n",
    "y_train = train.label.values\n",
    "#y_valid = val_data.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T08:51:48.744133Z",
     "iopub.status.busy": "2021-11-30T08:51:48.743917Z",
     "iopub.status.idle": "2021-11-30T08:51:48.865087Z",
     "shell.execute_reply": "2021-11-30T08:51:48.864427Z",
     "shell.execute_reply.started": "2021-11-30T08:51:48.744110Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((x_train, y_train))\n",
    "    .repeat()\n",
    "    .shuffle(2048)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    "    \n",
    ")\n",
    "test_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(x_test)\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T08:51:48.866723Z",
     "iopub.status.busy": "2021-11-30T08:51:48.866012Z",
     "iopub.status.idle": "2021-11-30T08:55:35.123690Z",
     "shell.execute_reply": "2021-11-30T08:55:35.122882Z",
     "shell.execute_reply.started": "2021-11-30T08:51:48.866687Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with strategy.scope():\n",
    "    transformer_layer = TFAutoModel.from_pretrained(MODEL)\n",
    "    model = build_model(transformer_layer, maxlen=MAX_LEN)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T08:55:35.125035Z",
     "iopub.status.busy": "2021-11-30T08:55:35.124810Z",
     "iopub.status.idle": "2021-11-30T08:59:37.067722Z",
     "shell.execute_reply": "2021-11-30T08:59:37.066830Z",
     "shell.execute_reply.started": "2021-11-30T08:55:35.124994Z"
    }
   },
   "outputs": [],
   "source": [
    "n_steps = x_train.shape[0] // BATCH_SIZE\n",
    "train_history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=n_steps,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T08:59:37.069742Z",
     "iopub.status.busy": "2021-11-30T08:59:37.069411Z",
     "iopub.status.idle": "2021-11-30T09:00:07.765005Z",
     "shell.execute_reply": "2021-11-30T09:00:07.763937Z",
     "shell.execute_reply.started": "2021-11-30T08:59:37.069705Z"
    }
   },
   "outputs": [],
   "source": [
    "y_t = model.predict(x_test, verbose=1)\n",
    "y_t = (y_t >= 0.5).astype(\"int\")\n",
    "result = pd.DataFrame({\"id\" :df_t.index, \"label\":y_t.squeeze() }, index = None )\n",
    "result.to_csv(\"result_transformer.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
